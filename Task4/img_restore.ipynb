{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"1.png\"></div>\n",
    "\n",
    "<div align=center><img src=\"2.png\"></div>\n",
    "\n",
    "<div align = 'center'>\n",
    "    <font size = '20'><b>本科实验报告</b></font>\n",
    "</div>\n",
    "\n",
    "<div align = 'center'>\n",
    "\n",
    "|   姓名：   |       沈骏一       |\n",
    "| :--------: | :----------------: |\n",
    "|   学院：   | 控制科学与工程学院 |\n",
    "|   专业：   |   自动化（控制）   |\n",
    "|   学号：   |     3200100259     |\n",
    "| 指导教师： |        姜伟        |\n",
    "</div>\n",
    "\n",
    "<div align = 'center'>\n",
    "    <font size = '5'><b>2023年5月9日</b></font>\n",
    "</div>\n",
    " <div align = 'center'>\n",
    "    <font size = '5'><b> DIP 图像复原</b></font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、任选一张清晰图像，模仿课件代码添加移动模糊或失焦模糊；\n",
    "\n",
    "2、实现逆滤波和其它复原方法（比如维纳滤波、有约束复原方法等），利用正确的PSF和不正确的PSF对模糊图像复原，展示复原结果；\n",
    "\n",
    "3、对步骤1移动模糊图像添加不同水平的噪声，重复步骤2工作；\n",
    "\n",
    "4、提交课程报告，内容包括各步骤代码和实现结果，并讨论各方法的优缺点。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加模糊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1600, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread('image.png')\n",
    "print(image.shape)\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mul(A, B):\n",
    "    ra, ca = A.shape\n",
    "    rb, cb = B.shape\n",
    "    r = ra + rb - 1\n",
    "    c = ca + cb - 1\n",
    "\n",
    "    a1 = np.pad(A, ((0, r - ra), (0, c - ca)), 'constant')\n",
    "    b1 = np.pad(B, ((0, r - rb), (0, c - cb)), 'constant')\n",
    "    fftA = np.fft.fft2(a1)\n",
    "    fftB = np.fft.fft2(b1)\n",
    "    result1 = np.fft.ifft2(fftA * fftB)\n",
    "\n",
    "    r_start = int(np.floor(rb / 2)) + 1\n",
    "    r_end = r_start + ra - 1\n",
    "    c_start = int(np.floor(cb / 2)) + 1\n",
    "    c_end = c_start + ca - 1\n",
    "    out = result1[r_start:r_end+1, c_start:c_end+1]\n",
    "    return out\n",
    "\n",
    "def div(A, B):\n",
    "    ra, ca = A.shape\n",
    "    rb, cb = B.shape\n",
    "    r = ra + rb - 1\n",
    "    c = ca + cb - 1\n",
    "\n",
    "    a1 = np.pad(A, ((0, r - ra), (0, c - ca)), 'constant')\n",
    "    b1 = np.pad(B, ((0, r - rb), (0, c - cb)), 'constant')\n",
    "    fftA = np.fft.fft2(a1)\n",
    "    fftB = np.fft.fft2(b1)+1e-8\n",
    "    result1 = np.fft.ifft2(fftA / fftB)\n",
    "\n",
    "    r_start = int(np.floor(rb / 2)) + 1\n",
    "    r_end = r_start + ra - 1\n",
    "    c_start = int(np.floor(cb / 2)) + 1\n",
    "    c_end = c_start + ca - 1\n",
    "    out = result1[r_start:r_end+1, c_start:c_end+1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def motion_blur(image, kernel_size=15):\n",
    "    kernel_motion_blur = np.zeros((kernel_size, kernel_size))\n",
    "    kernel_motion_blur[int((kernel_size-1)/2), :] = np.ones(kernel_size)\n",
    "    cv2.normalize(src= kernel_motion_blur, dst= kernel_motion_blur, norm_type = cv2.NORM_L1)\n",
    "    #blurred = cv2.filter2D(image, -1, kernel_motion_blur)\n",
    "    blurred = np.zeros_like(image)\n",
    "    f_kernel_motion_blur = np.fft.fft2(kernel_motion_blur,s=(image.shape[0],image.shape[1]))\n",
    "    for i in range(3):\n",
    "        f_image = np.fft.fft2(image[:,:,i])\n",
    "        f_image = f_image * f_kernel_motion_blur\n",
    "        f_image = np.fft.ifft2(f_image)\n",
    "        f_image = np.abs(f_image)\n",
    "        blurred[:,:,i] = f_image / f_image.max() * 255\n",
    "\n",
    "    \n",
    "    return blurred,kernel_motion_blur,f_kernel_motion_blur\n",
    "\n",
    "motion_blurred_image,kernel_motion_blur,f_kernel_motion_blur = motion_blur(image)\n",
    "cv2.imshow('Motion Blurred Image', motion_blurred_image)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10037\\AppData\\Local\\Temp\\ipykernel_22988\\3891836310.py:8: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  blurred[:,:,i] = mul(image[:,:,i],kernel_motion_blur)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def motion_blur(image, kernel_size=15):\n",
    "    kernel_motion_blur = np.zeros((kernel_size, kernel_size))\n",
    "    kernel_motion_blur[int((kernel_size-1)/2), :] = np.ones(kernel_size)\n",
    "    cv2.normalize(src= kernel_motion_blur, dst= kernel_motion_blur, norm_type = cv2.NORM_L1)\n",
    "    #blurred = cv2.filter2D(image, -1, kernel_motion_blur)\n",
    "    blurred = np.zeros_like(image)\n",
    "    for i in range(3):\n",
    "        blurred[:,:,i] = mul(image[:,:,i],kernel_motion_blur)\n",
    "\n",
    "    \n",
    "    return blurred,kernel_motion_blur,f_kernel_motion_blur\n",
    "\n",
    "motion_blurred_image,kernel_motion_blur,f_kernel_motion_blur = motion_blur(image)\n",
    "cv2.imshow('Motion Blurred Image', motion_blurred_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def defocus_blur(image, kernel_size=15):\n",
    "    kernel_defocus_blur = np.ones((kernel_size, kernel_size))\n",
    "    cv2.normalize(src= kernel_defocus_blur, dst= kernel_defocus_blur, norm_type = cv2.NORM_L1)\n",
    "    #blurred = cv2.filter2D(image, -1, kernel_defocus_blur)\n",
    "    blurred = np.zeros_like(image)\n",
    "    f_kernel_defocus_blur = np.fft.fft2(kernel_defocus_blur,s=(image.shape[0],image.shape[1]))\n",
    "    for i in range(3):\n",
    "        f_image = np.fft.fft2(image[:,:,i])\n",
    "        f_image = f_image * f_kernel_defocus_blur\n",
    "        f_image = np.fft.ifft2(f_image)\n",
    "        f_image = np.abs(f_image)\n",
    "        blurred[:,:,i] = f_image / f_image.max() * 255\n",
    "        \n",
    "\n",
    "    return blurred,kernel_defocus_blur\n",
    "\n",
    "defocus_blurred_image,kernel_defocus_blur = defocus_blur(image)\n",
    "cv2.imshow('Defocus Blurred Image', defocus_blurred_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10037\\AppData\\Local\\Temp\\ipykernel_22988\\2110375411.py:7: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  blurred[:,:,i] = mul(image[:,:,i],kernel_defocus_blur)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def defocus_blur(image, kernel_size=15):\n",
    "    kernel_defocus_blur = np.ones((kernel_size, kernel_size))\n",
    "    cv2.normalize(src= kernel_defocus_blur, dst= kernel_defocus_blur, norm_type = cv2.NORM_L1)\n",
    "    #blurred = cv2.filter2D(image, -1, kernel_motion_blur)\n",
    "    blurred = np.zeros_like(image)\n",
    "    for i in range(3):\n",
    "        blurred[:,:,i] = mul(image[:,:,i],kernel_defocus_blur)\n",
    "\n",
    "    \n",
    "    return blurred,kernel_defocus_blur\n",
    "\n",
    "defocus_blurred_image,kernel_defocus_blur = defocus_blur(image)\n",
    "cv2.imshow('Defocus Blurred Image', defocus_blurred_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inverse_filter(image, psf):\n",
    "    inversed = np.zeros_like(image)\n",
    "    psf_fft = np.fft.fft2(psf,s=(image.shape[0],image.shape[1]))+1e-6\n",
    "    for i in range(3):\n",
    "        f_image = np.fft.fft2(image[:,:,i])\n",
    "        f_image = f_image / psf_fft\n",
    "        f_image = np.fft.ifft2(f_image)\n",
    "        f_image = np.abs(f_image)\n",
    "        inversed[:,:,i] = f_image / f_image.max() * 255\n",
    "    return inversed.astype(np.uint8)\n",
    "\n",
    "inverse_restored_image_from_motion_blur = inverse_filter(motion_blurred_image, kernel_motion_blur)\n",
    "cv2.imshow('Inverse Restored Image from Motion Blur', inverse_restored_image_from_motion_blur)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10037\\AppData\\Local\\Temp\\ipykernel_22988\\1595068668.py:4: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  inversed[:,:,i] = div(image[:,:,i],psf)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inverse_filter(image, psf):\n",
    "    inversed = np.zeros_like(image)\n",
    "    for i in range(3):\n",
    "        inversed[:,:,i] = div(image[:,:,i],psf)\n",
    "    return inversed.astype(np.uint8)\n",
    "\n",
    "inverse_restored_image_from_motion_blur = inverse_filter(motion_blurred_image, kernel_motion_blur)\n",
    "cv2.imshow('Inverse Restored Image from Motion Blur', inverse_restored_image_from_motion_blur)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_filter(image, psf, k=0.01):\n",
    "    for i in range(3):\n",
    "        input_fft = np.fft.fft2(image[:,:,i])\n",
    "        psf_fft = np.fft.fft2(psf[:,:,i]) + 1e-8\n",
    "        psf_fft_conj = np.conj(psf_fft)\n",
    "        result = np.fft.ifft2((psf_fft_conj) / (psf_fft * psf_fft_conj + k) * input_fft)\n",
    "        result = np.abs(result)\n",
    "        image[:,:,i] = result / result.max() * 255\n",
    "    return image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_psf = np.zeros_like(motion_blurred_image)\n",
    "motion_psf[:, int(motion_psf.shape[1]/2-motion_kernel_size/2):int(motion_psf.shape[1]/2+motion_kernel_size/2)] = 1/motion_kernel_size\n",
    "inverse_restored_image_from_motion_blur = inverse_filter(motion_blurred_image, motion_psf)\n",
    "wiener_restored_image_from_motion_blur = wiener_filter(motion_blurred_image, motion_psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (900,1600) (61,61) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m defocus_psf \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((defocus_psf0\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],defocus_psf0\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\u001b[39m3\u001b[39m))\n\u001b[0;32m      3\u001b[0m defocus_psf[:,:,\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m defocus_psf[:,:,\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m defocus_psf0\n\u001b[1;32m----> 4\u001b[0m inverse_restored_image_from_defocus_blur \u001b[39m=\u001b[39m inverse_filter(defocus_blurred_image, defocus_psf)\n\u001b[0;32m      5\u001b[0m wiener_restored_image_from_defocus_blur \u001b[39m=\u001b[39m wiener_filter(defocus_blurred_image, defocus_psf)\n",
      "Cell \u001b[1;32mIn[91], line 5\u001b[0m, in \u001b[0;36minverse_filter\u001b[1;34m(image, psf)\u001b[0m\n\u001b[0;32m      3\u001b[0m input_fft \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfft\u001b[39m.\u001b[39mfft2(image[:,:,i])\n\u001b[0;32m      4\u001b[0m psf_fft \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfft\u001b[39m.\u001b[39mfft2(psf[:,:,i]) \u001b[39m+\u001b[39m \u001b[39m1e-8\u001b[39m\n\u001b[1;32m----> 5\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfft\u001b[39m.\u001b[39mifft2(input_fft \u001b[39m/\u001b[39;49m psf_fft)\n\u001b[0;32m      6\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(result)\n\u001b[0;32m      7\u001b[0m image[:,:,i] \u001b[39m=\u001b[39m result \u001b[39m/\u001b[39m result\u001b[39m.\u001b[39mmax() \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (900,1600) (61,61) "
     ]
    }
   ],
   "source": [
    "defocus_psf0 = cv2.getGaussianKernel(defocus_kernel_size*4+1, defocus_kernel_size) * cv2.getGaussianKernel(defocus_kernel_size*4+1, defocus_kernel_size).T\n",
    "defocus_psf = np.zeros((defocus_psf0.shape[0],defocus_psf0.shape[1],3))\n",
    "defocus_psf[:,:,1] = defocus_psf[:,:,2] = defocus_psf0\n",
    "inverse_restored_image_from_defocus_blur = inverse_filter(defocus_blurred_image, defocus_psf)\n",
    "wiener_restored_image_from_defocus_blur = wiener_filter(defocus_blurred_image, defocus_psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Motion Blurred Image', motion_blurred_image)\n",
    "cv2.imshow('Defocus Blurred Image', defocus_blurred_image)\n",
    "cv2.imshow('Inverse Restored Image from Motion Blur', inverse_restored_image_from_motion_blur)\n",
    "#cv2.imshow('Wiener Restored Image from Motion Blur', wiener_restored_image_from_motion_blur)\n",
    "#cv2.imshow('Inverse Restored Image from Defocus Blur', inverse_restored_image_from_defocus_blur)\n",
    "#cv2.imshow('Wiener Restored Image from Defocus Blur', wiener_restored_image_from_defocus_blur)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
